# app.py
# -*- coding: utf-8 -*-
"""
ğŸ§  ê¸°ì–µ ë²ˆì—­ ìˆœì„œ ê²Œì„ â€” ì™„ì „ ì˜¤í”„ë¼ì¸ ë²„ì „ (Streamlit)
- ë¡œì»¬ ëª¨ë¸ë§Œ ì‚¬ìš© (Hugging Faceì— ì ‘ì†í•˜ì§€ ì•ŠìŒ)
- ìƒì„±: ./models/flan-t5-small (google/flan-t5-small ë‚´ë ¤ë°›ì•„ ë°°ì¹˜)
- ë²ˆì—­: ./models/m2m100_418M  (facebook/m2m100_418M ë‚´ë ¤ë°›ì•„ ë°°ì¹˜)
- ê¸°ëŠ¥: ëœë¤ ë‹¨ì–´ â†’ ì§§ì€ ì˜ì–´ ë¬¸ì¥ ìƒì„± â†’ í•œêµ­ì–´ ë²ˆì—­(íŒíŠ¸) â†’ ë‹¨ì–´ ì…”í”Œ â†’ ìˆœì„œ ë§íˆê¸°
"""

import os, re, random, time
from typing import List

import streamlit as st
import pandas as pd

# ğŸ”’ ì™¸ë¶€ ì ‘ì† ì™„ì „ ì°¨ë‹¨ (ì˜¤í”„ë¼ì¸ ë³´ì¦)
os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["TRANSFORMERS_OFFLINE"] = "1"

# ====== ê²½ë¡œ/ì„¤ì • ======
FLAN_DIR = "./models/flan-t5-small"
M2M_DIR  = "./models/m2m100_418M"

CSV_PATH = "Concreteness_english.csv"
WORD_COL = "Word"

MAX_WORDS       = 6     # ìƒì„± ë¬¸ì¥ ìµœëŒ€ ë‹¨ì–´ ìˆ˜(ë‚œì´ë„)
MAX_NEW_TOKENS  = 24
RETRIES_GEN     = 6     # ë‹¨ì–´ í¬í•¨/ê¸¸ì´ ì¡°ê±´ ì¬ì‹œë„
RETRIES_WORDS   = 50    # ì ë‹¹í•œ ê¸¸ì´ ë¬¸ì¥ ë½‘ê¸° ì¬ì‹œë„

WORD_RE = re.compile(r"[A-Za-z']+")

# ====== Streamlit ê¸°ë³¸ ======
st.set_page_config(page_title="ê¸°ì–µ ë²ˆì—­ ìˆœì„œ ê²Œì„ (ì˜¤í”„ë¼ì¸)", page_icon="ğŸ§ ", layout="centered")
st.title("ğŸ§  ê¸°ì–µ ë²ˆì—­ ìˆœì„œ ê²Œì„ (ì˜¤í”„ë¼ì¸)")
st.caption("ëª¨ë¸ê³¼ ë°ì´í„°ëŠ” ë¡œì»¬ì—ì„œë§Œ ì½ìŠµë‹ˆë‹¤. ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬ ì ‘ì† ì—†ìŒ.")

# ====== ê²½ë¡œ ì¡´ì¬ ì ê²€ ======
missing = [p for p in [FLAN_DIR, M2M_DIR] if not os.path.isdir(p)]
if missing:
    st.error("ë‹¤ìŒ ë¡œì»¬ ëª¨ë¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ í´ë”ë¥¼ ì¤€ë¹„í•´ ì£¼ì„¸ìš”:")
    for p in missing:
        st.code(os.path.abspath(p))
    st.stop()

# ====== ìœ í‹¸ ======
def tokenize_words(text: str) -> List[str]:
    return WORD_RE.findall(text)

def enforce_sentence_end(s: str) -> str:
    s = s.strip()
    if not re.search(r"[.!?]$", s):
        s += "."
    return s

def within_limit(tokens: List[str], lo=3, hi=MAX_WORDS) -> bool:
    return lo <= len(tokens) <= hi

def is_tautology(sent: str, word: str) -> bool:
    """'river is a river' ê°™ì€ ì •ì˜ë¬¸/ì¤‘ë³µ íŒ¨í„´ íšŒí”¼"""
    w = re.escape(word.lower())
    return bool(re.search(rf"\b{w}\b\s+is\s+(a|the)?\s*\b{w}\b", sent.lower()))

# ====== ëª¨ë¸ ë¡œë”© (ë¡œì»¬ì—ì„œë§Œ) ======
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline, set_seed
set_seed(1337)

@st.cache_resource(show_spinner=False)
def load_generator_local():
    tok = AutoTokenizer.from_pretrained(FLAN_DIR, local_files_only=True)
    mdl = AutoModelForSeq2SeqLM.from_pretrained(FLAN_DIR, local_files_only=True)
    return pipeline("text2text-generation", model=mdl, tokenizer=tok, device=-1)

@st.cache_resource(show_spinner=False)
def load_en2ko_local():
    tok = AutoTokenizer.from_pretrained(M2M_DIR, local_files_only=True)
    mdl = AutoModelForSeq2SeqLM.from_pretrained(M2M_DIR, local_files_only=True)
    # M2M100ì€ src_lang/tgt_lang í•„ìˆ˜
    return pipeline("translation", model=mdl, tokenizer=tok,
                    src_lang="en", tgt_lang="ko", device=-1)

# ====== ë°ì´í„° ë¡œë”© ======
@st.cache_data(show_spinner=False)
def load_wordlist() -> List[str]:
    if os.path.exists(CSV_PATH):
        try:
            df = pd.read_csv(CSV_PATH)
            if WORD_COL in df.columns:
                words = (df[WORD_COL].astype(str).str.strip().str.lower()
                         .dropna().unique().tolist())
                words = [w for w in words if w.isalpha() and len(w) >= 2]
            else:
                words = []
        except Exception:
            words = []
    else:
        words = []
    if not words:
        # í´ë°± ìƒ˜í”Œ
        words = ["apple", "river", "music", "future", "pattern", "me", "friend", "time"]
    return words

WORDS = load_wordlist()

# ====== ìƒì„±/ë²ˆì—­ ======
def build_prompt(word: str) -> str:
    # ë‹¨ì–´ 1íšŒë§Œ, ì •ì˜ë¬¸ íšŒí”¼ ì§€ì‹œ ì¶”ê°€
    return (f"Write one natural English sentence under {MAX_WORDS} words "
            f"that uses the word '{word}' exactly once. "
            f"Avoid definitions like \"{word} is a {word}\" and keep it conversational.")

def generate_sentence_with_word(gen_pipe, word: str) -> str:
    word = word.lower()
    for _ in range(RETRIES_GEN):
        out = gen_pipe(build_prompt(word),
                       max_new_tokens=MAX_NEW_TOKENS,
                       do_sample=False, num_return_sequences=1)[0]["generated_text"]
        out = enforce_sentence_end(out)
        toks = tokenize_words(out)
        has_word = re.search(rf"\b{re.escape(word)}\b", out, flags=re.IGNORECASE) is not None
        if has_word and within_limit(toks) and not is_tautology(out, word):
            # ë‹¨ì–´ 2ë²ˆ ì´ìƒ ë“±ì¥ë„ ê±¸ëŸ¬ë³´ê¸°(ì§€ì‹œ ìœ„ë°˜ ì¼€ì´ìŠ¤)
            if len(re.findall(rf"\b{re.escape(word)}\b", out, flags=re.IGNORECASE)) <= 2:
                return out
    # í´ë°±(í•­ìƒ ë‹¨ì–´ í¬í•¨, ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ)
    if word == "me":
        return "This is me."
    return f"I like {word}."

def translate_en2ko(trans_pipe, text: str) -> str:
    return trans_pipe(text, max_new_tokens=MAX_NEW_TOKENS)[0]["translation_text"]

# ====== ì‹œê°ì  ë¡œë”©: ë°ì´í„°+ëª¨ë¸ ======
def load_resources_ui():
    with st.status("ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì¤‘â€¦", expanded=True) as status:
        t0 = time.perf_counter()
        status.write("â‘  ë‹¨ì–´ ëª©ë¡ ë¡œë“œ")
        st.session_state.WORDS = WORDS
        st.dataframe(pd.DataFrame({"Word": WORDS[:50]}),
                     use_container_width=True, height=200)
        status.write(f"â†’ ë‹¨ì–´ {len(WORDS):,}ê°œ ì¤€ë¹„")

        status.write("â‘¡ ìƒì„± ëª¨ë¸ ë¡œë“œ (flan-t5-small, ì˜¤í”„ë¼ì¸)")
        st.session_state.gen = load_generator_local()

        status.write("â‘¢ ë²ˆì—­ ëª¨ë¸ ë¡œë“œ (m2m100_418M, ì˜¤í”„ë¼ì¸)")
        st.session_state.tr  = load_en2ko_local()

        status.write("â‘£ ì›Œë°ì—…")
        _ = st.session_state.gen("Write a short sentence with 'time'.", max_new_tokens=12)
        _ = st.session_state.tr("Hello world.", max_new_tokens=12)

        status.update(label=f"ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì™„ë£Œ ({time.perf_counter()-t0:.1f}s)", state="complete")
    st.session_state.models_ready = True

# ====== ê²Œì„ ë¼ìš´ë“œ ======
def new_round():
    WORDS_LOCAL = st.session_state.WORDS
    for _ in range(RETRIES_WORDS):
        w = random.choice(WORDS_LOCAL)
        s = generate_sentence_with_word(st.session_state.gen, w)
        toks = tokenize_words(s)
        if within_limit(toks):
            break
    else:
        w, s, toks = "me", "This is me.", ["This", "is", "me"]

    shuffled = toks[:]
    random.shuffle(shuffled)

    st.session_state.round_id     = st.session_state.get("round_id", 0) + 1
    st.session_state.word         = w
    st.session_state.sent_en      = s
    st.session_state.sent_ko      = translate_en2ko(st.session_state.tr, s)
    st.session_state.tokens       = toks
    st.session_state.shuffled     = shuffled
    st.session_state.selected_idx = []
    st.session_state.correct      = None
    st.session_state.hint_on      = False

    if "score" not in st.session_state:
        st.session_state.score = {"correct": 0, "total": 0}

# ====== ì‚¬ì´ë“œë°”: ë¡œë“œ ë²„íŠ¼ ======
if "models_ready" not in st.session_state:
    st.session_state.models_ready = False
if "WORDS" not in st.session_state:
    st.session_state.WORDS = None

with st.sidebar:
    st.header("âš™ï¸ ë¦¬ì†ŒìŠ¤")
    if not st.session_state.models_ready:
        if st.button("ë¦¬ì†ŒìŠ¤ ë¡œë“œ", use_container_width=True):
            load_resources_ui()
    else:
        st.success("ëª¨ë¸/ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ(ì˜¤í”„ë¼ì¸)")
        st.write(f"ë‹¨ì–´ ìˆ˜: **{len(st.session_state.WORDS):,}**")
        st.write("Â· ìƒì„±: flan-t5-small (local)")
        st.write("Â· ë²ˆì—­: m2m100_418M (local)")

# ì¤€ë¹„ ì•ˆ ëìœ¼ë©´ ì¤‘ë‹¨
if not st.session_state.models_ready:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ **ë¦¬ì†ŒìŠ¤ ë¡œë“œ**ë¥¼ ë¨¼ì € ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    st.stop()

# ì²« ë¼ìš´ë“œ
if "round_id" not in st.session_state:
    new_round()

# ====== ë³¸ë¬¸ UI ======
c1, c2, c3 = st.columns([1, 3, 1])
with c1: st.metric("ë¼ìš´ë“œ", st.session_state.round_id)
with c2: st.metric("í•œêµ­ì–´ íŒíŠ¸", st.session_state.sent_ko)
with c3: st.metric("ë‹¨ì–´ ìˆ˜", len(st.session_state.tokens))

st.divider()
st.subheader("ë‹¨ì–´ë¥¼ ìˆœì„œëŒ€ë¡œ ëˆŒëŸ¬ ë¬¸ì¥ì„ ì™„ì„±í•˜ì„¸ìš”")

shuf = st.session_state.shuffled
sel  = st.session_state.selected_idx
cols = st.columns(len(shuf))
for i, tok in enumerate(shuf):
    disabled = (i in sel) or (st.session_state.correct is True)
    with cols[i]:
        if st.button(tok, key=f"tok_{st.session_state.round_id}_{i}",
                     disabled=disabled, use_container_width=True):
            if i not in st.session_state.selected_idx:
                st.session_state.selected_idx.append(i)
            st.rerun()

chosen = [shuf[i] for i in sel]
st.write("ë‹¹ì‹ ì˜ ì„ íƒ:", " ".join(chosen) if chosen else "â€”")

b1, b2, b3, b4, b5 = st.columns(5)
with b1:
    if st.button("ì„ íƒ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.selected_idx = []
        st.session_state.correct = None
        st.rerun()
with b2:
    if st.button("ì¬ì…”í”Œ", use_container_width=True):
        random.shuffle(st.session_state.shuffled)
        st.session_state.selected_idx = []
        st.session_state.correct = None
        st.rerun()
with b3:
    if st.button("íŒíŠ¸ í† ê¸€", use_container_width=True):
        st.session_state.hint_on = not st.session_state.hint_on
        st.rerun()
with b4:
    if st.button("ì •ë‹µ í™•ì¸", type="primary", use_container_width=True):
        if len(st.session_state.selected_idx) == len(st.session_state.tokens):
            pred = [shuf[i] for i in st.session_state.selected_idx]
            gold = st.session_state.tokens
            ok = ([p.lower() for p in pred] == [g.lower() for g in gold])
            st.session_state.correct = ok
            st.session_state.score["total"] += 1
            if ok: st.session_state.score["correct"] += 1
        else:
            st.warning("ëª¨ë“  ë‹¨ì–´ë¥¼ ìˆœì„œëŒ€ë¡œ ì„ íƒí•´ ì£¼ì„¸ìš”!")
        st.rerun()
with b5:
    if st.button("ë‹¤ìŒ ë¼ìš´ë“œ â–¶", use_container_width=True):
        new_round()
        st.rerun()

st.divider()
if st.session_state.correct is True:
    st.success("âœ… ì •ë‹µ!  ì›ë¬¸: " + st.session_state.sent_en)
elif st.session_state.correct is False:
    st.error("âŒ ì˜¤ë‹µ!  ì›ë¬¸: " + st.session_state.sent_en)

if st.session_state.hint_on and st.session_state.correct is not True:
    st.info("íŒíŠ¸(ì²« ë‹¨ì–´): **" + st.session_state.tokens[0] + "**")

st.divider()
sc = st.session_state.score
acc = (sc["correct"] / sc["total"] * 100) if sc["total"] else 0.0
st.write(f"**ìŠ¤ì½”ì–´:** {sc['correct']} / {sc['total']}  (ì •í™•ë„ {acc:.1f}%)")
